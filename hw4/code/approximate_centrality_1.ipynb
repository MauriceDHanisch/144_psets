{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vioE_ucBJYd"
      },
      "source": [
        "# Approximate betweenness centrality using neural networks\n",
        "Here we start to approximate the betweennesss centrality using neural networks over a peer-2-peer network Gnutella. Gnutella is a set of datasets consisting of 9 networks ranging from 6,300 to 63,000 nodes. Our goal is to train a neural network on the smallest Gnurella graph and evaluate it on a much larger graph. We will guide you through this step by step.\n",
        "\n",
        "You can find Gnutella datasets at http://snap.stanford.edu/data/index.html. We will use p2p-Gnutella08 for training and p2p-Gnutella04 for testing.\n",
        "\n",
        "Note:\n",
        "1. Copy this notebook to your Google drive in order to execute it.\n",
        "2. Make sure to upload the data files in HW4 to your google drive and to modify their corresponding directories in the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW0BOZ4yfmCv"
      },
      "source": [
        "# Part 1: Training a model on Gnutella 08"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKHtNFA5EadN"
      },
      "source": [
        "## Preprocessing Gnutella08 dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uKKzWmx3EYbG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5Hg8LdYOElHB"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2jSO_ZIiwUFX"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "\n",
        "# choose an embedding size for Structure2Vec\n",
        "EMBED_SIZE = 64\n",
        "\n",
        "# choose number of dense layers in the neural network\n",
        "NUM_LAYERS = 5\n",
        "\n",
        "# choose number of folds for cross validation\n",
        "NUM_FOLD = 5\n",
        "\n",
        "# choose number of epochs for training\n",
        "NUM_EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EIuSDB1JEmpg"
      },
      "outputs": [],
      "source": [
        "# Normalize a list of values\n",
        "# NO NEED TO CHANGE\n",
        "\n",
        "def _normalize_array_by_rank(true_value, nr_nodes):\n",
        "  # true_value is a list of values you want to normalize and nr_nodes is the number of nodes in the list\n",
        "\n",
        "  rank = np.argsort(true_value, kind='mergesort', axis=None) #deg list get's normalised\n",
        "  norm = np.empty([nr_nodes])\n",
        "\n",
        "  for i in range(0, nr_nodes):\n",
        "\n",
        "    norm[rank[i]] = float(i+1) / float(nr_nodes)\n",
        "\n",
        "  max = np.amax(norm)\n",
        "  min = np.amin(norm)\n",
        "  if max > 0.0 and max > min:\n",
        "    for i in range(0, nr_nodes):\n",
        "      norm[i] = 2.0*(float(norm[i] - min) / float(max - min)) - 1.0\n",
        "  else:\n",
        "    print(\"Max value = 0\")\n",
        "\n",
        "  return norm, rank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JHQb00GNE0Av"
      },
      "outputs": [],
      "source": [
        "#Read in and create NetworkX Graph; G\n",
        "\n",
        "#TO-DO: The path needs to be changed according to your dataset directory in your GOOGLE DRIVE\n",
        "path = '../data/p2p-Gnutella08.txt'\n",
        "\n",
        "G = nx.read_edgelist(path, comments='#', delimiter=None, create_using=nx.DiGraph,\n",
        "                  nodetype=None, data=True, edgetype=None, encoding='utf-8')\n",
        "\n",
        "#print(nx.info(G))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tMXmUw9HFL3h"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deg_lst: \n",
            " [10, 1, 6, 87, 69, 83, 1, 60, 84, 59, 7, 15, 4, 7, 17, 12, 2, 15, 1, 3, 2, 79, 2, 11, 11, 2, 13, 7, 6, 1, 11, 54, 95, 50, 80, 70, 90, 91, 80, 92, 19, 90, 75, 79, 23, 52, 30, 5, 5, 7, 17, 23, 12, 16, 21, 14, 1, 2, 9, 87, 76, 21, 67, 48, 91, 56, 14, 1, 6, 6, 16, 2, 39, 4, 1, 17, 20, 2, 4, 97, 71, 81, 94, 91, 40, 8, 10, 14, 6, 6, 5, 12, 4, 2, 67, 57, 69, 11, 1, 4, 12, 15, 5, 6, 3, 4, 13, 2, 1, 13, 2, 10, 15, 2, 3, 1, 12, 5, 9, 14, 37, 15, 25, 4, 5, 13, 3, 12, 2, 6, 5, 2, 7, 13, 5, 4, 19, 7, 16, 83, 72, 19, 14, 8, 6, 16, 20, 5, 3, 2, 2, 14, 20, 12, 12, 11, 11, 11, 12, 2, 2, 13, 1, 30, 12, 1, 5, 2, 16, 11, 9, 5, 15, 3, 1, 3, 4, 7, 4, 15, 17, 7, 2, 18, 1, 8, 15, 4, 6, 13, 3, 10, 2, 12, 3, 7, 10, 4, 1, 3, 3, 17, 7, 5, 1, 5, 4, 14, 7, 6, 3, 2, 4, 4, 11, 2, 12, 10, 11, 5, 4, 12, 11, 12, 20, 15, 14, 2, 1, 5, 14, 12, 14, 13, 3, 14, 12, 12, 3, 27, 2, 11, 2, 2, 14, 9, 6, 3, 13, 1, 1, 5, 1, 1, 4, 7, 1, 2, 2, 9, 12, 4, 4, 5, 17, 9, 14, 25, 13, 4, 2, 5, 7, 11, 4, 5, 4, 4, 1, 10, 12, 12, 5, 1, 6, 1, 15, 1, 14, 17, 13, 9, 9, 9, 5, 2, 4, 10, 14, 18, 16, 14, 1, 10, 20, 4, 13, 15, 1, 12, 13, 11, 18, 4, 3, 9, 13, 3, 16, 1, 1, 1, 2, 15, 16, 11, 13, 2, 3, 14, 4, 16, 1, 3, 13, 8, 5, 2, 4, 11, 11, 11, 7, 4, 2, 12, 4, 10, 3, 1, 77, 25, 13, 1, 45, 11, 1, 14, 1, 3, 4, 4, 12, 3, 15, 4, 18, 6, 4, 4, 1, 5, 15, 6, 9, 3, 10, 2, 4, 7, 3, 13, 6, 19, 15, 72, 82, 76, 44, 5, 3, 1, 1, 13, 17, 12, 11, 1, 14, 2, 3, 16, 15, 4, 5, 4, 13, 15, 15, 3, 2, 4, 11, 10, 18, 14, 16, 21, 4, 7, 15, 9, 4, 4, 8, 14, 1, 2, 2, 15, 2, 3, 14, 6, 11, 15, 19, 27, 7, 3, 14, 6, 13, 18, 5, 2, 1, 13, 12, 13, 14, 14, 89, 9, 14, 6, 11, 14, 4, 15, 12, 12, 79, 82, 3, 4, 2, 9, 2, 4, 5, 6, 3, 3, 69, 79, 65, 3, 21, 10, 20, 13, 11, 3, 1, 1, 13, 3, 10, 4, 6, 11, 66, 22, 2, 24, 4, 16, 4, 13, 12, 3, 2, 2, 13, 15, 4, 12, 13, 3, 12, 2, 3, 16, 5, 11, 16, 13, 3, 12, 3, 20, 16, 11, 17, 12, 3, 20, 13, 12, 14, 4, 3, 3, 1, 1, 12, 2, 6, 4, 7, 4, 10, 13, 3, 7, 2, 5, 2, 5, 12, 8, 8, 14, 16, 3, 88, 2, 10, 25, 65, 16, 13, 3, 12, 13, 3, 12, 1, 72, 51, 13, 2, 1, 12, 7, 4, 21, 4, 11, 2, 14, 15, 12, 1, 2, 2, 1, 2, 1, 1, 3, 14, 4, 19, 15, 14, 9, 8, 16, 1, 14, 2, 16, 2, 3, 13, 19, 13, 14, 4, 1, 2, 91, 5, 4, 4, 10, 11, 2, 1, 9, 2, 1, 13, 17, 43, 11, 13, 10, 14, 22, 13, 2, 2, 2, 2, 41, 15, 1, 15, 7, 32, 3, 6, 3, 12, 1, 3, 3, 3, 9, 16, 3, 2, 1, 11, 12, 12, 5, 11, 5, 1, 1, 4, 2, 1, 15, 3, 1, 1, 2, 1, 2, 1, 1, 5, 10, 11, 11, 14, 11, 1, 1, 15, 4, 1, 3, 1, 3, 2, 2, 2, 41, 21, 16, 1, 12, 1, 11, 12, 11, 14, 9, 6, 12, 10, 7, 3, 2, 3, 1, 21, 10, 18, 2, 16, 6, 2, 5, 6, 3, 12, 3, 3, 12, 3, 12, 2, 2, 1, 2, 13, 11, 1, 3, 3, 3, 8, 2, 1, 5, 5, 8, 2, 2, 17, 8, 4, 20, 2, 5, 5, 15, 3, 4, 11, 2, 4, 3, 6, 11, 12, 8, 5, 12, 22, 6, 5, 10, 6, 1, 14, 2, 15, 2, 11, 3, 2, 3, 14, 14, 17, 5, 5, 2, 1, 2, 5, 9, 7, 13, 8, 3, 6, 15, 13, 10, 1, 1, 4, 10, 1, 14, 1, 13, 1, 1, 8, 1, 5, 2, 3, 3, 3, 1, 16, 11, 5, 9, 12, 4, 5, 14, 7, 4, 3, 3, 12, 2, 5, 3, 2, 1, 1, 16, 1, 3, 1, 17, 13, 1, 8, 14, 11, 3, 12, 14, 12, 1, 8, 26, 14, 1, 8, 1, 3, 1, 5, 2, 3, 2, 3, 9, 6, 3, 1, 19, 1, 8, 10, 19, 6, 6, 12, 1, 3, 1, 15, 4, 15, 13, 6, 2, 11, 12, 15, 4, 13, 3, 4, 4, 13, 3, 1, 7, 12, 4, 4, 1, 7, 4, 13, 1, 1, 3, 7, 8, 2, 16, 5, 16, 15, 9, 8, 12, 11, 2, 1, 13, 4, 9, 2, 14, 3, 13, 15, 4, 3, 5, 5, 7, 3, 7, 14, 5, 7, 4, 2, 1, 2, 13, 1, 16, 8, 25, 4, 14, 11, 14, 2, 3, 19, 8, 2, 5, 2, 3, 5, 9, 4, 16, 11, 80, 32, 13, 5, 4, 20, 12, 1, 2, 12, 11, 4, 5, 17, 1, 12, 1, 16, 7, 9, 4, 16, 11, 15, 11, 2, 4, 12, 5, 5, 9, 2, 15, 1, 4, 1, 3, 7, 7, 5, 12, 13, 7, 1, 3, 5, 4, 10, 3, 2, 4, 2, 1, 1, 1, 9, 12, 12, 5, 2, 22, 16, 1, 3, 6, 6, 5, 2, 17, 1, 3, 8, 12, 1, 15, 14, 1, 12, 1, 1, 2, 3, 3, 7, 2, 4, 16, 7, 12, 1, 1, 12, 14, 4, 6, 13, 6, 3, 12, 14, 20, 12, 6, 5, 4, 8, 11, 2, 11, 12, 2, 11, 7, 14, 5, 14, 7, 13, 10, 16, 12, 6, 17, 16, 2, 11, 6, 16, 1, 3, 2, 11, 4, 3, 3, 16, 13, 4, 12, 17, 13, 2, 12, 14, 16, 3, 3, 1, 6, 13, 13, 7, 14, 1, 11, 7, 3, 3, 13, 16, 2, 1, 12, 14, 3, 16, 3, 4, 14, 14, 14, 15, 2, 18, 2, 17, 1, 16, 13, 5, 4, 7, 4, 13, 12, 4, 2, 13, 21, 8, 2, 1, 10, 12, 11, 2, 1, 1, 11, 3, 14, 11, 1, 4, 11, 2, 29, 5, 15, 11, 2, 12, 12, 17, 1, 16, 13, 2, 1, 17, 13, 14, 3, 14, 8, 16, 1, 15, 6, 3, 14, 10, 11, 8, 1, 1, 4, 1, 13, 7, 6, 5, 19, 10, 14, 1, 7, 13, 13, 7, 13, 2, 13, 20, 4, 2, 18, 7, 18, 2, 17, 7, 18, 12, 2, 1, 1, 4, 3, 12, 10, 9, 13, 1, 9, 15, 11, 2, 2, 16, 12, 14, 13, 23, 4, 2, 3, 10, 4, 12, 2, 1, 3, 2, 6, 7, 1, 13, 17, 14, 10, 5, 12, 16, 1, 13, 2, 3, 9, 4, 16, 5, 4, 1, 12, 1, 18, 16, 4, 5, 6, 4, 2, 3, 1, 1, 3, 3, 10, 15, 2, 13, 12, 1, 1, 1, 1, 1, 5, 22, 1, 2, 1, 2, 11, 10, 8, 3, 11, 7, 8, 17, 3, 1, 1, 6, 1, 2, 1, 13, 3, 9, 3, 3, 16, 4, 4, 13, 1, 12, 18, 10, 3, 12, 11, 8, 13, 7, 3, 8, 13, 16, 3, 2, 3, 3, 15, 2, 7, 6, 4, 11, 16, 1, 4, 12, 12, 5, 6, 4, 15, 19, 4, 15, 8, 13, 4, 1, 10, 17, 1, 9, 1, 1, 1, 14, 11, 5, 20, 13, 4, 9, 12, 1, 14, 1, 6, 11, 8, 7, 7, 2, 10, 1, 1, 2, 18, 12, 3, 1, 7, 5, 4, 2, 8, 2, 4, 2, 6, 5, 3, 16, 16, 1, 5, 12, 9, 10, 15, 12, 18, 1, 7, 8, 15, 15, 12, 8, 13, 5, 1, 1, 5, 1, 1, 1, 13, 14, 3, 19, 12, 12, 12, 1, 5, 13, 14, 3, 1, 13, 14, 2, 1, 4, 1, 1, 11, 11, 13, 14, 3, 15, 18, 2, 13, 6, 13, 12, 5, 6, 10, 2, 1, 6, 12, 16, 4, 5, 5, 15, 1, 6, 11, 16, 1, 24, 24, 2, 6, 5, 5, 1, 5, 3, 4, 1, 15, 11, 6, 1, 2, 12, 15, 2, 1, 11, 12, 1, 2, 6, 1, 12, 1, 4, 14, 10, 1, 7, 1, 14, 9, 3, 5, 1, 12, 13, 11, 7, 18, 9, 3, 22, 5, 9, 3, 3, 5, 6, 6, 5, 6, 2, 4, 13, 9, 1, 11, 3, 3, 13, 6, 11, 3, 16, 1, 5, 4, 7, 13, 6, 11, 4, 12, 12, 2, 10, 7, 1, 3, 11, 2, 1, 12, 1, 1, 16, 1, 6, 12, 2, 1, 1, 11, 2, 1, 1, 6, 3, 1, 2, 15, 4, 5, 16, 16, 1, 1, 4, 13, 10, 5, 5, 6, 1, 15, 5, 5, 14, 2, 1, 12, 12, 1, 1, 18, 14, 2, 13, 22, 13, 3, 4, 11, 2, 1, 5, 3, 1, 4, 3, 7, 1, 4, 25, 1, 1, 14, 14, 22, 3, 14, 1, 13, 1, 14, 5, 14, 13, 2, 12, 2, 11, 1, 3, 12, 2, 1, 2, 7, 4, 2, 12, 12, 3, 2, 15, 13, 4, 12, 3, 3, 4, 1, 8, 14, 14, 3, 4, 5, 5, 11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 11, 1, 4, 2, 18, 13, 13, 5, 9, 4, 4, 3, 11, 2, 12, 12, 11, 1, 2, 3, 4, 7, 1, 4, 12, 20, 2, 4, 11, 2, 6, 15, 9, 14, 11, 3, 5, 11, 1, 3, 12, 1, 3, 1, 1, 4, 10, 3, 13, 13, 3, 13, 12, 16, 14, 1, 6, 12, 12, 7, 4, 4, 2, 1, 11, 1, 13, 1, 14, 6, 7, 14, 9, 2, 1, 1, 3, 4, 14, 14, 2, 3, 2, 1, 8, 14, 2, 11, 10, 5, 6, 2, 7, 15, 1, 13, 12, 18, 10, 2, 1, 2, 14, 6, 12, 13, 4, 15, 4, 5, 3, 12, 1, 5, 1, 11, 2, 4, 4, 1, 1, 7, 20, 11, 6, 12, 2, 11, 9, 1, 13, 3, 1, 2, 2, 2, 3, 2, 4, 3, 12, 12, 11, 2, 13, 7, 15, 1, 1, 1, 11, 11, 13, 10, 5, 6, 4, 1, 2, 1, 2, 14, 3, 2, 3, 2, 5, 10, 3, 8, 6, 2, 3, 3, 1, 2, 1, 12, 11, 1, 1, 1, 12, 15, 2, 16, 6, 8, 12, 14, 12, 12, 1, 12, 3, 2, 16, 8, 2, 23, 3, 13, 25, 14, 2, 11, 1, 2, 1, 11, 2, 12, 13, 12, 17, 2, 4, 15, 15, 4, 3, 12, 13, 2, 16, 13, 1, 2, 3, 15, 10, 8, 5, 12, 5, 13, 3, 4, 1, 10, 3, 5, 4, 3, 4, 5, 2, 11, 1, 4, 7, 4, 21, 1, 6, 3, 12, 12, 11, 3, 2, 9, 12, 1, 11, 4, 3, 14, 21, 13, 14, 13, 13, 13, 13, 5, 11, 3, 1, 11, 1, 4, 17, 2, 11, 1, 3, 15, 2, 2, 14, 6, 7, 3, 7, 2, 6, 3, 1, 2, 9, 7, 7, 12, 11, 1, 5, 1, 9, 3, 4, 5, 17, 13, 4, 4, 1, 15, 18, 14, 16, 5, 14, 3, 16, 12, 12, 10, 12, 2, 14, 2, 2, 3, 17, 4, 3, 3, 13, 1, 1, 3, 4, 10, 4, 3, 14, 1, 19, 2, 5, 14, 10, 1, 12, 3, 1, 5, 11, 12, 1, 4, 14, 1, 2, 7, 6, 13, 13, 7, 4, 18, 2, 1, 16, 4, 12, 1, 3, 7, 2, 1, 11, 1, 3, 4, 19, 13, 4, 3, 12, 1, 14, 2, 3, 2, 1, 2, 2, 1, 11, 13, 2, 12, 12, 11, 5, 2, 2, 2, 1, 4, 10, 3, 13, 9, 20, 24, 3, 1, 5, 1, 12, 11, 2, 1, 9, 13, 2, 7, 14, 1, 2, 2, 4, 2, 1, 11, 15, 17, 13, 9, 2, 12, 2, 12, 14, 6, 4, 2, 13, 2, 2, 13, 13, 1, 5, 5, 12, 1, 3, 13, 3, 3, 5, 14, 10, 12, 4, 2, 2, 13, 2, 5, 5, 2, 3, 2, 13, 12, 1, 14, 14, 5, 2, 15, 2, 16, 11, 3, 14, 13, 7, 1, 13, 1, 16, 13, 12, 7, 3, 3, 1, 1, 12, 16, 7, 2, 5, 3, 3, 5, 5, 1, 4, 2, 4, 2, 15, 4, 3, 13, 1, 5, 1, 1, 1, 4, 2, 6, 8, 2, 1, 5, 4, 2, 5, 6, 1, 1, 5, 3, 1, 2, 5, 2, 1, 2, 2, 14, 11, 1, 10, 1, 2, 2, 6, 1, 7, 7, 4, 1, 1, 2, 15, 10, 2, 1, 13, 1, 14, 1, 6, 5, 15, 3, 5, 2, 2, 5, 4, 3, 13, 4, 13, 14, 16, 6, 1, 4, 3, 14, 13, 5, 3, 11, 12, 2, 13, 3, 14, 14, 15, 3, 1, 1, 3, 12, 6, 3, 13, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 11, 4, 16, 1, 13, 13, 16, 9, 2, 3, 4, 1, 2, 1, 17, 1, 4, 2, 15, 1, 2, 3, 1, 1, 2, 5, 11, 11, 3, 12, 1, 11, 1, 3, 1, 11, 3, 3, 1, 4, 13, 1, 12, 11, 2, 1, 2, 14, 2, 3, 2, 5, 3, 2, 2, 4, 16, 4, 2, 12, 12, 1, 10, 16, 11, 1, 15, 2, 1, 2, 11, 1, 1, 11, 8, 13, 1, 30, 4, 3, 4, 1, 17, 4, 2, 3, 6, 14, 2, 13, 3, 16, 2, 1, 1, 4, 3, 15, 14, 12, 5, 5, 1, 6, 2, 1, 17, 1, 3, 11, 13, 1, 13, 3, 16, 8, 13, 4, 1, 2, 11, 4, 16, 1, 13, 11, 1, 20, 11, 4, 16, 16, 2, 1, 1, 11, 1, 13, 1, 13, 30, 13, 4, 13, 13, 4, 11, 5, 2, 1, 3, 12, 10, 2, 1, 4, 13, 13, 4, 1, 4, 12, 17, 1, 13, 14, 10, 2, 20, 13, 2, 4, 1, 6, 5, 4, 4, 4, 1, 9, 11, 2, 12, 13, 3, 16, 2, 3, 1, 7, 11, 14, 2, 1, 10, 1, 11, 4, 6, 12, 1, 11, 13, 4, 1, 2, 1, 2, 1, 4, 1, 8, 1, 4, 1, 15, 2, 14, 4, 1, 3, 15, 17, 14, 3, 12, 13, 12, 1, 1, 1, 11, 11, 5, 6, 14, 12, 1, 7, 2, 13, 5, 7, 1, 11, 1, 18, 13, 3, 11, 10, 1, 7, 4, 3, 15, 12, 15, 4, 1, 1, 11, 11, 10, 1, 7, 4, 7, 1, 4, 5, 8, 1, 10, 4, 4, 5, 2, 1, 1, 2, 3, 11, 3, 12, 4, 2, 11, 1, 4, 1, 11, 3, 1, 12, 12, 2, 2, 4, 1, 1, 1, 7, 15, 4, 9, 2, 2, 2, 2, 12, 12, 1, 5, 2, 1, 2, 6, 5, 1, 7, 13, 10, 3, 11, 1, 12, 14, 6, 6, 5, 1, 11, 2, 14, 9, 1, 1, 2, 7, 2, 2, 2, 9, 2, 1, 11, 1, 10, 8, 2, 4, 4, 2, 3, 4, 5, 10, 12, 1, 7, 1, 8, 4, 13, 1, 2, 2, 3, 1, 3, 4, 1, 3, 2, 3, 2, 1, 2, 14, 11, 12, 14, 12, 14, 13, 7, 1, 5, 4, 1, 2, 13, 12, 11, 12, 11, 1, 1, 15, 15, 11, 6, 11, 15, 2, 43, 12, 15, 1, 11, 11, 14, 1, 11, 6, 1, 11, 15, 8, 10, 11, 11, 11, 10, 13, 1, 1, 15, 1, 1, 1, 1, 1, 2, 3, 13, 2, 16, 7, 17, 2, 1, 11, 15, 2, 2, 1, 10, 15, 10, 4, 6, 3, 3, 3, 19, 12, 1, 3, 2, 6, 10, 1, 1, 4, 1, 1, 1, 1, 2, 1, 2, 12, 10, 2, 13, 11, 13, 3, 1, 1, 1, 33, 12, 11, 11, 3, 6, 3, 10, 1, 8, 11, 11, 1, 11, 10, 12, 1, 12, 1, 13, 1, 4, 5, 13, 1, 3, 5, 4, 1, 1, 6, 1, 4, 14, 11, 13, 1, 5, 2, 2, 5, 14, 15, 3, 15, 15, 3, 5, 9, 2, 10, 1, 1, 13, 16, 2, 24, 2, 1, 2, 13, 1, 1, 4, 1, 12, 12, 13, 12, 5, 17, 2, 1, 2, 12, 5, 2, 21, 16, 4, 9, 1, 6, 2, 1, 12, 1, 3, 2, 2, 10, 4, 15, 3, 13, 4, 5, 6, 2, 5, 13, 1, 13, 4, 2, 9, 4, 2, 1, 3, 3, 1, 2, 1, 2, 17, 13, 2, 2, 2, 5, 4, 3, 10, 11, 1, 13, 13, 4, 12, 1, 1, 1, 2, 4, 1, 1, 1, 4, 3, 4, 2, 9, 1, 1, 3, 4, 5, 11, 8, 10, 14, 12, 1, 12, 18, 3, 15, 13, 1, 4, 1, 16, 10, 2, 1, 21, 1, 16, 2, 14, 3, 11, 2, 1, 1, 11, 10, 6, 14, 1, 1, 1, 3, 1, 1, 23, 11, 2, 3, 4, 1, 1, 2, 11, 2, 3, 1, 13, 1, 12, 6, 5, 4, 3, 3, 8, 13, 2, 11, 3, 1, 1, 5, 12, 14, 4, 7, 2, 4, 12, 1, 2, 7, 1, 2, 6, 3, 14, 12, 1, 2, 12, 1, 10, 1, 14, 6, 6, 14, 11, 8, 2, 2, 1, 1, 3, 16, 1, 1, 12, 2, 11, 4, 4, 16, 2, 3, 4, 4, 13, 6, 18, 7, 11, 1, 4, 16, 4, 12, 1, 11, 2, 4, 1, 11, 5, 13, 12, 10, 13, 4, 13, 13, 13, 4, 4, 4, 2, 10, 1, 1, 14, 4, 13, 3, 1, 6, 3, 2, 3, 3, 3, 12, 1, 11, 1, 15, 4, 2, 16, 14, 2, 12, 11, 5, 1, 7, 11, 14, 13, 2, 4, 13, 2, 11, 15, 2, 1, 2, 1, 13, 1, 1, 2, 10, 11, 13, 5, 12, 13, 12, 1, 10, 12, 2, 1, 3, 1, 2, 6, 11, 3, 1, 2, 12, 14, 1, 13, 7, 3, 2, 12, 2, 2, 2, 3, 8, 4, 11, 12, 1, 1, 5, 11, 3, 12, 12, 13, 2, 3, 12, 1, 12, 1, 7, 6, 1, 4, 1, 3, 16, 13, 2, 5, 3, 6, 3, 2, 1, 1, 10, 1, 8, 1, 1, 1, 1, 10, 1, 10, 19, 2, 1, 13, 6, 2, 1, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 11, 2, 11, 1, 2, 3, 5, 1, 6, 2, 10, 1, 4, 1, 11, 1, 3, 3, 10, 2, 1, 10, 1, 3, 1, 3, 12, 16, 12, 1, 1, 2, 1, 2, 2, 11, 12, 2, 15, 10, 1, 1, 1, 3, 4, 5, 10, 5, 14, 1, 3, 11, 1, 13, 3, 6, 10, 12, 17, 3, 14, 4, 12, 2, 2, 11, 12, 7, 5, 3, 1, 8, 3, 1, 9, 3, 1, 3, 14, 10, 12, 1, 2, 2, 2, 2, 16, 1, 11, 3, 13, 2, 1, 8, 14, 12, 11, 12, 2, 7, 1, 13, 1, 10, 3, 11, 1, 3, 3, 1, 2, 12, 11, 11, 3, 1, 12, 4, 14, 3, 12, 3, 1, 9, 1, 10, 3, 12, 7, 2, 2, 11, 11, 2, 16, 7, 1, 12, 3, 1, 3, 1, 12, 2, 2, 10, 3, 4, 12, 14, 11, 11, 4, 2, 5, 1, 3, 4, 2, 3, 12, 2, 3, 1, 1, 1, 14, 10, 10, 10, 12, 7, 2, 1, 10, 1, 2, 6, 2, 10, 1, 3, 15, 2, 1, 1, 3, 2, 11, 1, 3, 9, 3, 1, 3, 1, 1, 15, 10, 3, 1, 9, 11, 4, 11, 13, 4, 13, 1, 1, 1, 4, 13, 4, 13, 6, 14, 3, 10, 12, 1, 1, 7, 2, 15, 2, 12, 12, 13, 11, 12, 2, 14, 11, 5, 2, 3, 11, 3, 13, 5, 3, 11, 15, 1, 10, 50, 12, 4, 1, 2, 1, 2, 1, 3, 2, 3, 1, 1, 1, 1, 12, 7, 2, 5, 1, 13, 1, 1, 1, 1, 2, 1, 1, 13, 1, 11, 4, 4, 3, 17, 2, 1, 10, 1, 11, 3, 1, 2, 13, 1, 1, 1, 6, 1, 1, 11, 12, 3, 1, 14, 1, 12, 13, 3, 3, 3, 4, 1, 9, 2, 14, 12, 11, 9, 2, 4, 14, 13, 4, 1, 1, 2, 1, 11, 1, 3, 1, 12, 13, 2, 3, 13, 12, 3, 2, 1, 10, 7, 10, 13, 2, 11, 6, 11, 1, 1, 1, 12, 11, 7, 17, 1, 1, 10, 13, 12, 11, 10, 4, 2, 4, 10, 12, 3, 1, 11, 11, 1, 13, 2, 11, 9, 7, 1, 11, 1, 5, 1, 4, 1, 1, 11, 12, 8, 2, 1, 8, 10, 2, 3, 12, 1, 3, 1, 11, 10, 4, 16, 1, 13, 1, 3, 6, 3, 1, 6, 1, 14, 2, 1, 3, 1, 1, 2, 13, 1, 10, 3, 9, 8, 12, 1, 3, 9, 12, 2, 14, 1, 1, 12, 1, 2, 11, 4, 3, 3, 11, 2, 2, 1, 12, 11, 11, 5, 12, 1, 1, 4, 1, 12, 14, 12, 12, 12, 11, 11, 13, 12, 2, 12, 1, 11, 3, 1, 13, 12, 1, 11, 1, 3, 12, 1, 1, 2, 1, 2, 11, 12, 2, 1, 9, 1, 3, 11, 3, 3, 4, 1, 1, 12, 1, 11, 3, 3, 1, 11, 5, 2, 3, 1, 4, 14, 2, 2, 10, 11, 1, 1, 13, 16, 6, 3, 1, 3, 9, 2, 1, 1, 2, 4, 9, 11, 1, 16, 17, 2, 1, 1, 4, 10, 3, 3, 2, 7, 4, 1, 1, 15, 2, 1, 6, 12, 4, 10, 1, 5, 11, 11, 12, 3, 2, 15, 1, 1, 2, 3, 1, 1, 1, 10, 2, 1, 12, 12, 12, 5, 2, 2, 3, 1, 13, 15, 1, 2, 7, 6, 2, 11, 4, 13, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 13, 1, 12, 2, 1, 1, 1, 1, 1, 1, 1, 3, 5, 2, 3, 4, 3, 3, 1, 1, 4, 1, 1, 11, 1, 1, 11, 3, 5, 12, 1, 2, 5, 17, 10, 1, 11, 2, 2, 3, 5, 3, 5, 1, 2, 1, 12, 2, 3, 14, 5, 3, 1, 2, 1, 3, 8, 1, 2, 2, 12, 15, 11, 3, 1, 1, 2, 4, 10, 4, 11, 1, 5, 2, 2, 2, 1, 2, 1, 11, 4, 2, 1, 1, 10, 2, 2, 3, 2, 1, 1, 2, 2, 1, 2, 1, 4, 11, 2, 3, 8, 2, 2, 1, 1, 17, 7, 2, 1, 12, 7, 1, 1, 3, 11, 1, 1, 3, 3, 11, 12, 1, 1, 3, 6, 1, 11, 1, 15, 13, 5, 3, 11, 14, 1, 1, 1, 1, 13, 2, 13, 14, 12, 2, 1, 19, 1, 13, 1, 18, 14, 2, 1, 2, 1, 1, 3, 1, 11, 1, 13, 2, 14, 9, 1, 1, 1, 2, 3, 11, 3, 4, 1, 2, 2, 1, 12, 11, 1, 1, 3, 7, 14, 1, 13, 3, 15, 1, 12, 14, 12, 6, 4, 2, 1, 1, 2, 1, 1, 4, 14, 11, 1, 1, 3, 1, 1, 11, 2, 12, 1, 6, 1, 1, 12, 13, 1, 1, 15, 13, 3, 1, 5, 3, 3, 1, 11, 1, 13, 12, 13, 3, 2, 1, 3, 2, 7, 1, 1, 4, 2, 1, 1, 3, 13, 2, 1, 1, 4, 3, 3, 13, 11, 14, 6, 2, 5, 3, 12, 1, 2, 12, 14, 8, 2, 13, 13, 3, 1, 13, 1, 1, 1, 1, 2, 12, 1, 12, 11, 2, 10, 1, 3, 1, 4, 4, 1, 4, 1, 4, 7, 11, 12, 11, 15, 12, 4, 1, 1, 2, 4, 2, 1, 1, 1, 3, 3, 1, 4, 1, 1, 2, 1, 12, 12, 14, 15, 1, 4, 10, 2, 1, 1, 1, 2, 2, 10, 1, 13, 2, 1, 11, 11, 1, 13, 5, 4, 3, 10, 2, 12, 14, 13, 4, 3, 6, 2, 11, 1, 2, 6, 2, 15, 12, 11, 5, 11, 1, 15, 2, 3, 1, 12, 4, 3, 2, 2, 11, 3, 1, 2, 1, 5, 2, 1, 2, 1, 2, 6, 12, 12, 1, 12, 4, 12, 2, 12, 2, 1, 3, 3, 2, 13, 4, 3, 2, 7, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 13, 3, 10, 10, 3, 12, 3, 12, 2, 3, 1, 2, 14, 1, 11, 2, 11, 4, 5, 12, 3, 12, 1, 12, 6, 3, 2, 2, 1, 1, 1, 1, 2, 15, 2, 7, 1, 1, 2, 13, 5, 3, 2, 12, 1, 4, 14, 2, 11, 12, 6, 13, 1, 1, 15, 11, 13, 12, 2, 2, 3, 3, 1, 3, 3, 1, 14, 2, 2, 1, 5, 5, 8, 11, 2, 10, 1, 2, 2, 3, 4, 4, 4, 4, 2, 1, 14, 3, 1, 1, 12, 11, 15, 16, 12, 1, 12, 6, 3, 2, 4, 2, 14, 1, 14, 3, 1, 1, 5, 11, 1, 2, 2, 1, 13, 1, 3, 11, 2, 12, 2, 1, 11, 11, 2, 1, 1, 2, 9, 11, 2, 1, 12, 1, 15, 1, 12, 2, 13, 7, 1, 12, 12, 10, 3, 10, 3, 14, 11, 2, 3, 11, 1, 14, 2, 12, 12, 11, 1, 2, 11, 2, 2, 1, 12, 11, 1, 1, 3, 12, 2, 6, 1, 10, 12, 1, 6, 5, 4, 2, 11, 11, 1, 11, 1, 3, 13, 12, 11, 2, 2, 2, 2, 12, 1, 11, 1, 4, 10, 2, 11, 13, 3, 1, 1, 13, 1, 3, 2, 4, 1, 2, 1, 2, 2, 3, 4, 2, 1, 3, 11, 12, 11, 1, 2, 11, 14, 1, 1, 20, 4, 16, 1, 15, 3, 12, 3, 14, 10, 2, 12, 1, 11, 1, 15, 3, 1, 13, 34, 11, 12, 5, 11, 1, 1, 2, 11, 1, 1, 3, 4, 1, 2, 2, 1, 15, 4, 9, 1, 1, 1, 13, 1, 2, 3, 1, 13, 1, 14, 6, 1, 13, 2, 1, 1, 2, 1, 2, 1, 2, 12, 2, 13, 7, 8, 12, 4, 11, 6, 1, 11, 2, 14, 3, 3, 1, 10, 1, 10, 4, 2, 1, 12, 1, 7, 2, 1, 4, 1, 4, 1, 1, 1, 3, 1, 2, 12, 1, 3, 10, 16, 2, 1, 1, 1, 1, 13, 11, 13, 1, 12, 10, 1, 7, 11, 2, 1, 11, 1, 1, 3, 1, 5, 2, 2, 1, 14, 11, 2, 11, 11, 1, 1, 1, 2, 7, 13, 11, 3, 2, 12, 11, 1, 3, 14, 6, 13, 11, 2, 2, 2, 12, 2, 4, 1, 12, 11, 11, 13, 3, 1, 11, 2, 2, 11, 4, 1, 10, 12, 11, 3, 1, 11, 13, 1, 3, 3, 1, 2, 2, 13, 11, 2, 11, 1, 7, 13, 11, 1, 1, 13, 1, 3, 3, 1, 2, 5, 3, 1, 11, 2, 2, 16, 1, 12, 3, 2, 3, 2, 10, 3, 3, 12, 2, 1, 11, 13, 5, 1, 2, 2, 4, 13, 1, 11, 2, 2, 11, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 2, 2, 2, 14, 3, 1, 1, 10, 12, 1, 1, 1, 2, 8, 1, 14, 2, 1, 1, 9, 13, 2, 1, 1, 13, 1, 1, 5, 1, 2, 1, 11, 2, 3, 1, 1, 1, 11, 11, 9, 11, 2, 1, 2, 11, 1, 1, 11, 5, 1, 2, 3, 13, 1, 13, 11, 4, 1, 1, 4, 1, 3, 11, 1, 1, 11, 3, 12, 2, 1, 1, 4, 1, 1, 12, 2, 2, 1, 1, 1, 1, 3, 2, 1, 1, 12, 1, 12, 1, 2, 1, 2, 2, 1, 15, 12, 1, 11, 2, 5, 12, 1, 12, 1, 11, 9, 1, 11, 2, 3, 1, 1, 1, 1, 10, 1, 2, 15, 8, 1, 3, 11, 1, 11, 3, 2, 2, 2, 1, 11, 8, 12, 11, 11, 2, 11, 3, 1, 1, 1, 5, 1, 2, 7, 2, 3, 6, 1, 1, 1, 12, 3, 1, 12, 1, 10, 1, 2, 6, 12, 13, 1, 1, 1, 1, 1, 1, 3, 1, 2, 11, 2, 1, 1, 1, 1, 2, 1, 2, 1, 3, 2, 12, 12, 1, 14, 10, 6, 11, 6, 12, 3, 11, 2, 11, 13, 4, 1, 1, 11, 13, 1, 1, 12, 13, 12, 1, 13, 1, 16, 1, 12, 12, 1, 11, 1, 11, 3, 3, 10, 1, 4, 13, 3, 4, 2, 1, 2, 1, 6, 3, 1, 2, 2, 12, 1, 3, 12, 4, 8, 2, 1, 1, 1, 3, 1, 7, 11, 3, 1, 12, 13, 13, 1, 1, 1, 15, 2, 11, 1, 11, 3, 3, 2, 1, 2, 2, 2, 12, 11, 11, 4, 2, 10, 1, 1, 3, 12, 4, 3, 14, 2, 11, 1, 1, 1, 1, 1, 2, 11, 1, 12, 1, 2, 1, 1, 11, 1, 1, 1, 13, 2, 1, 1, 1, 11, 1, 2, 2, 5, 10, 11, 1, 1, 1, 1, 2, 1, 1, 11, 1, 2, 4, 3, 11, 12, 5, 1, 13, 3, 4, 2, 9, 1, 1, 1, 4, 12, 1, 4, 1, 4, 11, 1, 1, 11, 1, 11, 11, 4, 1, 1, 13, 6, 2, 3, 4, 11, 1, 1, 3, 5, 2, 2, 2, 2, 1, 7, 2, 1, 2, 1, 2, 1, 1, 5, 2, 3, 1, 2, 11, 1, 1, 1, 1, 4, 1, 2, 1, 11, 1, 4, 11, 1, 11, 1, 3, 13, 1, 2, 2, 1, 1, 2, 10, 3, 12, 1, 1, 2, 1, 2, 6, 4, 12, 6, 1, 11, 3, 4, 1, 2, 2, 1, 1, 1, 3, 10, 1, 2, 1, 1, 1, 2, 1, 3, 1, 2, 14, 2, 11, 1, 1, 2, 1, 1, 3, 5, 2, 1, 2, 2, 1, 10, 1, 1, 1, 11, 3, 1, 1, 11, 3, 11, 2, 1, 3, 1, 1, 11, 14, 3, 1, 2, 1, 1, 2, 11, 1, 2, 2, 11, 1, 2, 1, 10, 2, 4, 1, 14, 1, 1, 12, 11, 1, 1, 1, 2, 11, 4, 3, 2, 3, 11, 11, 1, 2, 1, 1, 11, 1, 1, 11, 11, 2, 2, 1, 12, 2, 2, 1, 1, 12, 1, 12, 1, 12, 1, 1, 2, 12, 11, 6, 4, 11, 1, 3, 11, 5, 12, 1, 3, 1, 11, 2, 1, 1, 2, 1, 1, 2, 2, 1, 13, 1, 3, 3, 12, 12, 11, 1, 3, 1, 1, 4, 1, 13, 1, 1, 11, 4, 1, 2, 3, 1, 1, 12, 1, 11, 1, 1, 11, 1, 2, 1, 11, 1, 7, 2, 1, 1, 1, 1, 2, 10, 11, 1, 10, 3, 2, 2, 2, 11, 1, 1, 11, 13, 2, 1, 1, 3, 11, 3, 2, 3, 12, 1, 2, 2, 11, 1, 1, 11, 12, 11, 1, 12, 11, 47, 1, 2, 1, 11, 11, 1, 1, 15, 1, 9, 10, 1, 2, 1, 1, 1, 13, 11, 2, 1, 1, 2, 11, 11, 3, 3, 1, 2, 1, 1, 1, 1, 1, 2, 11, 1, 11, 13, 11, 1, 6, 1, 2, 11, 1, 1, 1, 1, 2, 1, 4, 1, 1, 11, 1, 2, 2, 2, 6, 1, 11, 2, 6, 1, 13, 4, 11, 2, 6, 1, 1, 2, 14, 1, 12, 1, 3, 2, 7, 2, 11, 2, 12, 1, 1, 2, 6, 3, 1, 2, 10, 1, 2, 1, 1, 2, 13, 2, 1, 11, 1, 2, 1, 13, 1, 2, 1, 6, 2, 1, 1, 1, 2, 1, 1, 12, 1, 2, 12, 2, 2, 2, 3, 2, 1, 18, 2, 2, 1, 13, 1, 1, 6, 5, 1, 11, 1, 1, 1, 1, 1, 1, 1, 1, 10, 1, 3, 2, 5, 1, 1, 2, 14, 1, 1, 1, 1, 12, 2, 10, 1, 2, 2, 1, 1, 11, 1, 2, 1, 3, 1, 2, 1, 1, 1, 1, 1, 13, 1, 4, 1, 1, 11, 1, 1, 1, 3, 1, 3, 1, 11, 3, 1, 1, 1, 2, 1, 11, 1, 13, 1, 2, 1, 1, 12, 1, 13, 1, 1, 11, 2, 3, 10, 1, 1, 1, 1, 1, 1, 2, 1, 4, 6, 3, 1, 1, 10, 2, 10, 1, 1, 2, 4, 11, 1, 1, 1, 3, 1, 1, 1, 11, 1, 11, 11, 4, 1, 1, 2, 1, 1, 11, 1, 11, 11, 7, 2, 11, 1, 13, 2, 3, 12, 1, 15, 10, 2, 1, 1, 3, 11, 3, 1, 2, 1, 1, 3, 1, 1, 12, 13, 11, 10, 1, 1, 2, 12, 2, 11, 1, 19, 4, 1, 6, 1, 2, 1, 1, 1, 12, 4, 1, 6, 2, 3, 2, 1, 1, 1, 1, 2, 1, 1, 11, 2, 2, 1, 1, 1, 1, 3, 11, 1, 7, 1, 3, 2, 1, 1, 2, 1, 11, 6, 1, 1, 3, 2, 1, 1, 6, 1, 1, 3, 2, 3, 12, 1, 3, 1, 2, 11, 1, 1, 1, 2, 11, 3, 13, 12, 11, 11, 1, 1, 1, 1, 2, 4, 11, 1, 10, 13, 3, 6, 1, 3, 1, 1, 1, 2, 2, 1, 11, 1, 1, 1, 1, 2, 10, 1, 11, 3, 2, 12, 1, 1, 11, 1, 1, 1, 1, 1, 11, 6, 1, 11, 1, 11, 1, 1, 3, 2, 1, 1, 1, 2, 1, 1, 1, 1, 11, 5, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 2, 1, 3, 1, 1, 2, 2, 2, 11, 1, 2, 2, 1, 1, 2, 10, 11, 1, 16, 1, 1, 1, 1, 2, 1, 11, 1, 1, 1, 1, 2, 1, 1, 2, 11, 1, 1, 2, 2, 2, 1, 2, 11, 2, 1, 11, 12, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 1, 11, 1, 10, 2, 3, 3, 1, 1, 1, 2, 1, 1, 1, 19, 1, 2, 1, 13, 10, 2, 2, 1, 2, 2, 12, 11, 11, 1, 1, 1, 2, 3, 1, 1, 11, 10, 1, 11, 11, 11, 1, 1, 1, 7, 5, 1, 1, 11, 12, 1, 3, 2, 11, 49, 1, 1, 6, 2, 1, 11, 1, 5, 1, 2, 1, 1, 1, 3, 10, 1, 1, 11, 11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 10, 11, 2, 1, 1, 1, 1, 11, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 14, 2, 1, 11, 11, 1, 11, 2, 1, 11, 1, 11, 1, 10, 1, 1, 2, 1, 5, 1, 11, 1, 1, 2, 11, 11, 1, 11, 1, 2, 1, 10, 1, 1, 1, 3, 1, 1, 1, 11, 2, 1, 11, 1, 1, 1, 1, 1, 11, 11, 12, 1, 11, 11, 5, 12, 1, 2, 1, 1, 11, 1, 1, 11, 2, 1, 1, 1, 1, 2, 12, 12, 12, 2, 12, 11, 11, 1, 1, 1, 1, 11, 14, 2, 11, 1, 2, 1, 11, 2, 1, 1, 1, 2, 1, 1, 10, 2, 10, 2, 2, 6, 12, 1, 1, 11, 2, 1, 11, 11, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 2, 12, 2, 1, 11, 11, 1, 1, 1, 1, 2, 1, 1, 1, 11, 1, 2, 11, 10, 1, 10, 11, 1, 1, 1, 1, 1, 11, 11, 10, 1, 9, 1, 1, 1, 1, 2, 10, 2, 1, 2, 10, 10, 3, 11, 12, 1, 2, 12, 1, 1, 11, 1, 1, 1, 11, 10, 2, 1, 1, 1, 1, 11, 1, 1, 1, 2, 2, 2, 11, 11, 11, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 11, 1, 11, 3, 42, 1, 11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 11, 1, 1, 10, 1, 1, 11, 1, 11, 11, 11, 11, 12, 2, 2, 1, 11, 10, 2, 1, 1, 2, 11, 1, 1, 1, 1, 11, 1, 1, 2, 1, 10, 5, 1, 1, 1, 12, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 11, 1, 1, 1, 2, 1, 1, 11, 1, 1, 2, 3, 11, 1, 1, 1, 1, 1, 1, 11, 1, 1, 1, 2, 1, 1, 1, 9, 1, 10, 1, 11, 1, 11, 1, 1, 1, 10, 1, 1, 3, 1, 11, 6, 1, 1, 1, 1, 1, 2, 6, 1, 10, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "# Creating list of Degrees of the nodes in G and normalising them:\n",
        "\n",
        "deg_lst = [val for (node, val) in G.degree()]\n",
        "nr_nodes = G.number_of_nodes()\n",
        "print(\"deg_lst: \\n\", deg_lst)\n",
        "\n",
        "degree_norm, degree_rank = _normalize_array_by_rank(deg_lst, nr_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "B4a79bglFRux"
      },
      "outputs": [],
      "source": [
        "# Computing Ground-truth values and normalising them:\n",
        "\n",
        "b = [v for v in nx.betweenness_centrality(G).values()]\n",
        "\n",
        "BC_norm_cent, BC_cent_rank = _normalize_array_by_rank(b, nr_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0q-1gU8FO9z6"
      },
      "outputs": [],
      "source": [
        "# Define Structure2Vec\n",
        "# NO NEED TO CHANGE\n",
        "\n",
        "def Structure2Vec(G, nr_nodes, degree_norm, num_features=1, embed_size=512, layers=2):\n",
        "\n",
        "  #build feature matrix\n",
        "  def get_degree(i):\n",
        "    return degree_norm[i]\n",
        "\n",
        "  def build_feature_matrix():\n",
        "    n = nr_nodes\n",
        "    feature_matrix = []\n",
        "    for i in range(0, n):\n",
        "      feature_matrix.append(get_degree(i))\n",
        "    return feature_matrix\n",
        "  #Structure2Vec node embedding\n",
        "  A = nx.to_numpy_array(G)\n",
        "\n",
        "  dim = [nr_nodes, num_features]\n",
        "\n",
        "\n",
        "  node_features = tf.cast(build_feature_matrix(), tf.float32)\n",
        "  node_features = tf.reshape(node_features, dim)\n",
        "\n",
        "  initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0,\n",
        "                                                                mode=\"fan_avg\",\n",
        "                                                                distribution=\"uniform\")\n",
        "  #print(initializer)\n",
        "\n",
        "  A = tf.sparse.from_dense(A)\n",
        "  A = tf.cast(A, tf.float32)\n",
        "  w1 = tf.Variable(initializer((num_features, embed_size)), trainable=True,\n",
        "                                  dtype=tf.float32, name=\"w1\")\n",
        "  w2 = tf.Variable(initializer((embed_size, embed_size)), trainable=True,\n",
        "                                  dtype=tf.float32, name=\"w2\")\n",
        "  w3 = tf.Variable(initializer((1,embed_size)), trainable=True, dtype=tf.float32, name=\"w3\")\n",
        "  w4 = tf.Variable(initializer([]), trainable=True, dtype=tf.float32, name=\"w4\")\n",
        "\n",
        "  wx_all = tf.matmul(node_features, w1)  # NxE\n",
        "\n",
        "  #computing X1:\n",
        "  #sparse.reduce_sum: Computes the sum of elements across dimensions of a SparseTensor.\n",
        "  weight_sum_init = tf.sparse.reduce_sum(A, axis=1, keepdims=True, ) #takes adjacency matrix\n",
        "  n_nodes = tf.shape(input=A)[1]\n",
        "\n",
        "  weight_sum = tf.multiply(weight_sum_init, w4)\n",
        "  weight_sum = tf.nn.relu(weight_sum)  # Nx1\n",
        "  weight_sum = tf.matmul(weight_sum, w3)  # NxE\n",
        "\n",
        "  weight_wx = tf.add(wx_all, weight_sum)\n",
        "  current_mu = tf.nn.relu(weight_wx)  # NxE = H^0\n",
        "\n",
        "  for i in range(0, layers):\n",
        "    neighbor_sum = tf.sparse.sparse_dense_matmul(A, current_mu)\n",
        "    neighbor_linear = tf.matmul(neighbor_sum, w2)  # NxE\n",
        "\n",
        "    current_mu = tf.nn.relu(tf.add(neighbor_linear, weight_wx))  # NxE\n",
        "\n",
        "  mu_all = current_mu\n",
        "\n",
        "  return mu_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "47p_VK_dRC5f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "W0000 00:00:1769887710.045252 2793227 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "# Converting the graph structure into vectors\n",
        "\n",
        "mu_all = Structure2Vec(G, nr_nodes, degree_norm, embed_size=EMBED_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J-8ogrRGFoO"
      },
      "source": [
        "## Training a Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mwflrFN6F6sx"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,337</span> (24.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,337\u001b[0m (24.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,337</span> (24.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,337\u001b[0m (24.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Building NN model\n",
        "\n",
        "UNITS = int(EMBED_SIZE/2)\n",
        "def build_model():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.Input(shape=(EMBED_SIZE,)))\n",
        "\n",
        "  # choose the number of layers to construct your network\n",
        "  for _ in range(NUM_LAYERS):\n",
        "    model.add(tf.keras.layers.Dense(UNITS, activation =\"relu\"))\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(1))\n",
        "  model.compile(optimizer='sgd', loss='mse')\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "model = build_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wSI-9-czGT9j"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([6301   64], shape=(2,), dtype=int32)\n",
            "tf.Tensor([6301], shape=(1,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# Construct training set and groundtruth\n",
        "\n",
        "x_train = mu_all\n",
        "y_train = BC_norm_cent\n",
        "print(tf.shape(x_train))\n",
        "print(tf.shape(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Ci1l6ODgGVX5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "tf.Tensor([5041   64], shape=(2,), dtype=int32)\n",
            "Epoch 1/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 409us/step - loss: nan\n",
            "Epoch 2/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 446us/step - loss: nan\n",
            "Epoch 3/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 403us/step - loss: nan\n",
            "Epoch 4/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 412us/step - loss: nan\n",
            "Epoch 4: early stopping\n",
            "model.metrics_names:  ['loss']\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - loss: nan\n",
            "[nan]\n",
            "processing fold # 1\n",
            "tf.Tensor([5041   64], shape=(2,), dtype=int32)\n",
            "Epoch 1/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 412us/step - loss: nan\n",
            "Epoch 2/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 406us/step - loss: nan\n",
            "Epoch 3/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 445us/step - loss: nan\n",
            "Epoch 4/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 423us/step - loss: nan\n",
            "Epoch 4: early stopping\n",
            "model.metrics_names:  ['loss']\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: nan\n",
            "[nan, nan]\n",
            "processing fold # 2\n",
            "tf.Tensor([5041   64], shape=(2,), dtype=int32)\n",
            "Epoch 1/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 399us/step - loss: nan\n",
            "Epoch 2/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 406us/step - loss: nan\n",
            "Epoch 3/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 394us/step - loss: nan\n",
            "Epoch 4/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 386us/step - loss: nan\n",
            "Epoch 4: early stopping\n",
            "model.metrics_names:  ['loss']\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: nan\n",
            "[nan, nan, nan]\n",
            "processing fold # 3\n",
            "tf.Tensor([5041   64], shape=(2,), dtype=int32)\n",
            "Epoch 1/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 418us/step - loss: nan\n",
            "Epoch 2/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 404us/step - loss: nan\n",
            "Epoch 3/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 404us/step - loss: nan\n",
            "Epoch 4/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 418us/step - loss: nan\n",
            "Epoch 4: early stopping\n",
            "model.metrics_names:  ['loss']\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: nan\n",
            "[nan, nan, nan, nan]\n",
            "processing fold # 4\n",
            "tf.Tensor([5041   64], shape=(2,), dtype=int32)\n",
            "Epoch 1/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 385us/step - loss: nan\n",
            "Epoch 2/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 416us/step - loss: nan\n",
            "Epoch 3/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410us/step - loss: nan\n",
            "Epoch 4/20\n",
            "\u001b[1m5041/5041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410us/step - loss: nan\n",
            "Epoch 4: early stopping\n",
            "model.metrics_names:  ['loss']\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: nan\n",
            "[nan, nan, nan, nan, nan]\n"
          ]
        }
      ],
      "source": [
        "# Computing cross validation\n",
        "# NO NEED TO CHANGE\n",
        "all_scores = []\n",
        "k = NUM_FOLD\n",
        "num_val_samples = len(x_train) // k\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = x_train[i*num_val_samples: (i+1) * num_val_samples]\n",
        "  val_targets = y_train[i*num_val_samples: (i+1)*num_val_samples]\n",
        "\n",
        "  partial_train_data = np.concatenate(\n",
        "      [x_train[:i*num_val_samples],\n",
        "      x_train[(i+1)*num_val_samples:]],\n",
        "      axis = 0)\n",
        "  print(tf.shape(partial_train_data))\n",
        "\n",
        "  partial_train_targets = np.concatenate(\n",
        "      [y_train[:i*num_val_samples],\n",
        "      y_train[(i+1)*num_val_samples:]],\n",
        "      axis = 0)\n",
        "\n",
        "  # Training\n",
        "  callbacks =  tf.keras.callbacks.EarlyStopping(\n",
        "      monitor= 'loss', min_delta=0, patience=3, verbose=1,\n",
        "      mode='auto', baseline=None, restore_best_weights=False)\n",
        "\n",
        "  model.fit(partial_train_data, partial_train_targets,\n",
        "            epochs = NUM_EPOCHS, batch_size = 1, callbacks = callbacks, verbose = 1)\n",
        "  print(\"model.metrics_names: \", model.metrics_names)\n",
        "\n",
        "  val_loss = model.evaluate(val_data, val_targets, verbose = 1)\n",
        "\n",
        "  all_scores.append(val_loss)\n",
        "  print(all_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "D6P1Y4USGzLk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step\n"
          ]
        }
      ],
      "source": [
        "# Computing Kendall on trained set\n",
        "\n",
        "x_new = x_train\n",
        "y_pred = model.predict(x_new)\n",
        "\n",
        "# compute kendalltau using the prediction results and the groundtruth\n",
        "from scipy import stats\n",
        "kendall_tau, p_value = scipy.stats.kendalltau(BC_norm_cent,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "kTI2M_cyJCqB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nan\n"
          ]
        }
      ],
      "source": [
        "# Print your kendalltau score\n",
        "# Make sure your kendalltau score is at least 0.70\n",
        "# PRINT HERE\n",
        "print(kendall_tau)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "brFQI-QBgYc1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "ename": "PermissionError",
          "evalue": "[Errno 13] Permission denied: '/content'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# You could save this model for part 2\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/content/drive/MyDrive/CS144/PS4/P1/GN08_model_plain.h5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/155/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:215\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:215\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
            "    \u001b[31m[... skipping similar frames: makedirs at line 215 (2 times)]\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:215\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:225\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
            "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: '/content'"
          ]
        }
      ],
      "source": [
        "# You could save this model for part 2\n",
        "\n",
        "model.save(\"/content/drive/MyDrive/CS144/PS4/P1/GN08_model_plain.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUWhQjCMfYWd"
      },
      "source": [
        "# Part 2: Evaluating the trained model on Gnutella 04\n",
        "\n",
        "Hints:\n",
        "1. Write down the evaluation using the functions and codes in Part 1\n",
        "2. Compute the groundtruth of betweenness centrality using NetworkX could take around 1 hour. Keep your Colab opened and be patient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bn7__itfjqZ"
      },
      "outputs": [],
      "source": [
        "'''Gnutella 04'''\n",
        "# change the path to your own directory\n",
        "path2 = '/content/drive/MyDrive/CS144/PS4/P1/p2p-Gnutella04.txt'\n",
        "\n",
        "G2 = nx.read_edgelist(path2, comments='#', delimiter=None, create_using=nx.DiGraph,\n",
        "                  nodetype=None, data=True, edgetype=None, encoding='utf-8')\n",
        "\n",
        "#print(nx.info(G2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "155",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
